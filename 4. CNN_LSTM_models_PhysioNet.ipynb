{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. CNN-LSTM models - PhysioNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1yWtUI6puRtxBOvLY5QRdo3VLnNQBj4M7",
      "authorship_tag": "ABX9TyPNAgbIES+Mu0ZkoysOa/BQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulkumar-datascientist/Detecting-Silent-Cardiac-Atrial-fibrillation-from-PPG-and-single-lead-ECG-Data-using-CNN-LSTM/blob/master/4.%20CNN_LSTM_models_PhysioNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zoVq3CVvEzb"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUVbCLU8vBmy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import os, os.path\n",
        "import matplotlib.pyplot as plt\n",
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "import zipfile\n",
        "import re\n",
        "import pickle\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Bidirectional, LSTM, Activation, Dense, Dropout, BatchNormalization, InputLayer, Conv1D, MaxPooling1D, Flatten\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import tensorflow as tf\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtx8accRnI0_"
      },
      "source": [
        "# Preparing the data according to the model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBdMqlhvp4-G",
        "outputId": "55c3112d-392f-49f1-d845-3f3a3e4525fc"
      },
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Galenband Project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Galenband Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiclA_BRp4-I"
      },
      "source": [
        "# loading the saved dataframe\n",
        "train_normalised                  = pd.read_pickle('Dataframes/Train_normalised.pkl')\n",
        "train_normalised_aug              = pd.read_pickle('Dataframes/Train_normalised_aug.pkl')\n",
        "\n",
        "test_normalised                   = pd.read_pickle('Dataframes/Test_normalised.pkl')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF59fNsfwTbx"
      },
      "source": [
        "### Function to prepare train, test and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UCdoq0zwK5K"
      },
      "source": [
        "def prepare_data(train_set, test_set, test_prop = 0.3):\n",
        "\n",
        "  # splitting the data into test and validation set\n",
        "  val_set, test_set = train_test_split(test_set, test_size=test_prop, random_state=42, shuffle=True)\n",
        "  \n",
        "  test_set.reset_index(drop=True, inplace=True)\n",
        "  val_set.reset_index(drop=True, inplace=True)\n",
        "\n",
        "  # Splitting into input and output variables\n",
        "  X_train = train_set.signals\n",
        "  Y_train = train_set.output_label\n",
        "\n",
        "  X_test = test_set.signals\n",
        "  Y_test = test_set.output_label\n",
        "\n",
        "  X_val = val_set.signals\n",
        "  Y_val = val_set.output_label\n",
        "\n",
        "  #####\n",
        "  input_train   = np.zeros((len(X_train), 9000), dtype='float32')\n",
        "  output_train = np.zeros(len(Y_train), dtype='float32')\n",
        "\n",
        "  input_test   = np.zeros((len(X_test), 9000), dtype='float32')\n",
        "  output_test = np.zeros(len(Y_test), dtype='float32')\n",
        "\n",
        "  input_val   = np.zeros((len(X_val), 9000), dtype='float32')\n",
        "  output_val = np.zeros(len(Y_val), dtype='float32')\n",
        "\n",
        "  # modeling X input\n",
        "  for index, value in enumerate(X_train):\n",
        "    input_train[index] = value[0]\n",
        "\n",
        "\n",
        "  for index, value in enumerate(X_test):\n",
        "    input_test[index] = value[0]\n",
        "\n",
        "\n",
        "  for index, value in enumerate(X_val):\n",
        "    input_val[index] = value[0]\n",
        "\n",
        "  \n",
        "  # class 0 = Normal, class 1 = Afib\n",
        "  # modeling Y output\n",
        "  for index,value in enumerate(Y_train):\n",
        "    if(value == 'N'):\n",
        "      output_train[index] = 0\n",
        "    else:\n",
        "      output_train[index] = 1\n",
        "\n",
        "  # modeling Y output\n",
        "  for index,value in enumerate(Y_test):\n",
        "    if(value == 'N'):\n",
        "      output_test[index] = 0\n",
        "    else:\n",
        "      output_test[index] = 1\n",
        "\n",
        "  # modeling Y output\n",
        "  for index,value in enumerate(Y_val):\n",
        "    if(value == 'N'):\n",
        "      output_val[index] = 0\n",
        "    else:\n",
        "      output_val[index] = 1\n",
        "\n",
        "  ## expanding the dimensions\n",
        "  input_train = input_train.reshape(len(input_train), 9000, 1)\n",
        "  output_train = output_train.reshape(len(output_train), 1)\n",
        "\n",
        "  input_test = input_test.reshape(len(input_test), 9000, 1)\n",
        "  output_test = output_test.reshape(len(output_test), 1)\n",
        "\n",
        "  input_val = input_val.reshape(len(input_val), 9000, 1)\n",
        "  output_val = output_val.reshape(len(output_val), 1)\n",
        "\n",
        "  ## return the data\n",
        "  return (input_train, output_train, input_test, output_test, input_val, output_val)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwaDwi6EnIpM"
      },
      "source": [
        "## 1.1 Model using Normal data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ-7ROCMzTSH"
      },
      "source": [
        "input_train, output_train, input_test, output_test, input_val, output_val = prepare_data(train_normalised, test_normalised, 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLlSS4Q4z3B3",
        "outputId": "da07aee3-0c17-47bf-e6d4-f4c4733a843a"
      },
      "source": [
        "print(\"input train shape:\\t \", input_train.shape)\n",
        "print(\"output train shape:\\t \", output_train.shape)\n",
        "\n",
        "print(\"\\ninput test shape:\\t \", input_test.shape)\n",
        "print(\"output test shape:\\t \", output_test.shape)\n",
        "\n",
        "print(\"\\ninput val shape:\\t \", input_val.shape)\n",
        "print(\"output val shape:\\t \", output_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input train shape:\t  (3975, 9000, 1)\n",
            "output train shape:\t  (3975, 1)\n",
            "\n",
            "input test shape:\t  (504, 9000, 1)\n",
            "output test shape:\t  (504, 1)\n",
            "\n",
            "input val shape:\t  (1176, 9000, 1)\n",
            "output val shape:\t  (1176, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1DdKe20ORt7",
        "outputId": "9c73513e-9626-4ccb-8c2a-4a1c4417223e"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(output_train.flatten()), output_train.flatten())\n",
        "\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "class_weight_dict\n",
        "\n",
        "class_weight_dict_1 = {0: 1.0, 1: 6.0}\n",
        "\n",
        "class_weight_dict_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0, 1: 6.0}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDZilOQEORt8"
      },
      "source": [
        "# Defining parameter values\n",
        "epochs          = 300\n",
        "batch_size      = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lW-I5OOsORt9",
        "outputId": "5c38ecce-84e5-4f49-9925-82224274fc89"
      },
      "source": [
        "model_1 = Sequential()\n",
        "\n",
        "# 64, 64, 32, 16, 8, 32\n",
        "\n",
        "input_shape = (9000, 1)\n",
        "model_1.add(InputLayer(input_shape=input_shape))\n",
        "\n",
        "model_1.add(Conv1D(64, 10,padding='causal', activation=\"tanh\"))\n",
        "model_1.add(MaxPooling1D(4))\n",
        "\n",
        "model_1.add(Conv1D(64, 10,padding='same', activation=\"tanh\"))\n",
        "model_1.add(MaxPooling1D(4))\n",
        "\n",
        "model_1.add(LSTM(32,activation = \"tanh\", return_sequences = True))\n",
        "model_1.add(LSTM(16, activation = \"tanh\", return_sequences = True))\n",
        "model_1.add(LSTM(8, activation = \"tanh\"))\n",
        "\n",
        "model_1.add(Dense(32, activation='tanh'))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 9000, 64)          704       \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 2250, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 2250, 64)          41024     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 562, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 562, 32)           12416     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 562, 16)           3136      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 8)                 800       \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 58,529\n",
            "Trainable params: 58,465\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBr3aRpyORt9"
      },
      "source": [
        "# model training configuration \n",
        "model_1.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                                    loss      = keras.losses.BinaryCrossentropy(),\n",
        "                                    metrics   = [keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "#SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Callback to reduce the learning rate when the validation loss has stopped improving\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 25, mode = 'min')\n",
        "\n",
        "# Callback to stop training the model when the validation loss has stopped improving\n",
        "# early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 40, mode = 'min')\n",
        "\n",
        "# CHECKPOINT callback\n",
        "filepath = \"Training_models/PhysioNet 2017/Model 1/ECG.epoch_{epoch:02d}.TL_{loss:.4f}.VL_{val_loss:.4f}.TA_{binary_accuracy:.2f}.VA_{val_binary_accuracy:.2f}.hdf5\"\n",
        "\n",
        "# Save training model when there is an improvement in validation_accuracy from the previous checkpint\n",
        "model_save = keras.callbacks.ModelCheckpoint(filepath, \n",
        "                                             monitor = 'val_binary_accuracy',\n",
        "                                             save_best_only=True, \n",
        "                                             mode = 'max')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_z73kRdORt-",
        "outputId": "39a09f64-acc8-4f57-9a8d-d090eb08013d"
      },
      "source": [
        "# Fitting the model\n",
        "model_1_his = model_1.fit(input_train, output_train,\n",
        "                      batch_size = batch_size , epochs = epochs, \n",
        "                      validation_data = (input_val, output_val),\n",
        "                      class_weight=class_weight_dict_1,\n",
        "                      callbacks=[reduce_lr,model_save])\n",
        "\n",
        "model_1.save('Training_models/PhysioNet 2017/Model 1/ECG_final_run.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "125/125 [==============================] - 29s 84ms/step - loss: 1.1144 - binary_accuracy: 0.5940 - val_loss: 0.6519 - val_binary_accuracy: 0.8869\n",
            "Epoch 2/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 1.0943 - binary_accuracy: 0.6483 - val_loss: 0.6184 - val_binary_accuracy: 0.7764\n",
            "Epoch 3/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 1.0382 - binary_accuracy: 0.6843 - val_loss: 0.5394 - val_binary_accuracy: 0.8316\n",
            "Epoch 4/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.9557 - binary_accuracy: 0.7150 - val_loss: 0.4119 - val_binary_accuracy: 0.8656\n",
            "Epoch 5/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.8892 - binary_accuracy: 0.7467 - val_loss: 1.1279 - val_binary_accuracy: 0.3750\n",
            "Epoch 6/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.8500 - binary_accuracy: 0.7713 - val_loss: 0.3193 - val_binary_accuracy: 0.8929\n",
            "Epoch 7/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.8592 - binary_accuracy: 0.7459 - val_loss: 0.5331 - val_binary_accuracy: 0.7389\n",
            "Epoch 8/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.7851 - binary_accuracy: 0.7839 - val_loss: 1.5626 - val_binary_accuracy: 0.1675\n",
            "Epoch 9/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.7423 - binary_accuracy: 0.7995 - val_loss: 4.1813 - val_binary_accuracy: 0.1071\n",
            "Epoch 10/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.7806 - binary_accuracy: 0.7834 - val_loss: 0.2497 - val_binary_accuracy: 0.9099\n",
            "Epoch 11/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.7039 - binary_accuracy: 0.7950 - val_loss: 0.4045 - val_binary_accuracy: 0.8282\n",
            "Epoch 12/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.6758 - binary_accuracy: 0.8028 - val_loss: 0.6344 - val_binary_accuracy: 0.6947\n",
            "Epoch 13/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.5687 - binary_accuracy: 0.8531 - val_loss: 0.4736 - val_binary_accuracy: 0.7372\n",
            "Epoch 14/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.5134 - binary_accuracy: 0.8684 - val_loss: 0.2506 - val_binary_accuracy: 0.8971\n",
            "Epoch 15/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.4652 - binary_accuracy: 0.8790 - val_loss: 0.4022 - val_binary_accuracy: 0.8308\n",
            "Epoch 16/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.4033 - binary_accuracy: 0.9019 - val_loss: 1.0886 - val_binary_accuracy: 0.5706\n",
            "Epoch 17/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.4093 - binary_accuracy: 0.8964 - val_loss: 1.6069 - val_binary_accuracy: 0.4167\n",
            "Epoch 18/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.4544 - binary_accuracy: 0.8833 - val_loss: 0.3123 - val_binary_accuracy: 0.8716\n",
            "Epoch 19/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.4006 - binary_accuracy: 0.9011 - val_loss: 0.1722 - val_binary_accuracy: 0.9362\n",
            "Epoch 20/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.3632 - binary_accuracy: 0.9122 - val_loss: 0.2136 - val_binary_accuracy: 0.9277\n",
            "Epoch 21/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.3757 - binary_accuracy: 0.9112 - val_loss: 0.5094 - val_binary_accuracy: 0.8010\n",
            "Epoch 22/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.3222 - binary_accuracy: 0.9180 - val_loss: 0.7820 - val_binary_accuracy: 0.6930\n",
            "Epoch 23/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2752 - binary_accuracy: 0.9358 - val_loss: 0.4241 - val_binary_accuracy: 0.8376\n",
            "Epoch 24/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.3044 - binary_accuracy: 0.9213 - val_loss: 0.2508 - val_binary_accuracy: 0.9048\n",
            "Epoch 25/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.3504 - binary_accuracy: 0.9145 - val_loss: 0.1885 - val_binary_accuracy: 0.9371\n",
            "Epoch 26/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2557 - binary_accuracy: 0.9394 - val_loss: 0.1829 - val_binary_accuracy: 0.9456\n",
            "Epoch 27/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2596 - binary_accuracy: 0.9346 - val_loss: 1.0013 - val_binary_accuracy: 0.6539\n",
            "Epoch 28/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2563 - binary_accuracy: 0.9411 - val_loss: 0.2940 - val_binary_accuracy: 0.8997\n",
            "Epoch 29/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2348 - binary_accuracy: 0.9394 - val_loss: 0.1766 - val_binary_accuracy: 0.9422\n",
            "Epoch 30/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2336 - binary_accuracy: 0.9421 - val_loss: 0.2424 - val_binary_accuracy: 0.9073\n",
            "Epoch 31/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.2012 - binary_accuracy: 0.9540 - val_loss: 0.2615 - val_binary_accuracy: 0.9150\n",
            "Epoch 32/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1990 - binary_accuracy: 0.9572 - val_loss: 0.1889 - val_binary_accuracy: 0.9405\n",
            "Epoch 33/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2122 - binary_accuracy: 0.9469 - val_loss: 1.4772 - val_binary_accuracy: 0.5748\n",
            "Epoch 34/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.2115 - binary_accuracy: 0.9532 - val_loss: 1.1706 - val_binary_accuracy: 0.6539\n",
            "Epoch 35/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1815 - binary_accuracy: 0.9555 - val_loss: 0.1822 - val_binary_accuracy: 0.9490\n",
            "Epoch 36/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1822 - binary_accuracy: 0.9580 - val_loss: 0.4709 - val_binary_accuracy: 0.8631\n",
            "Epoch 37/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1608 - binary_accuracy: 0.9658 - val_loss: 0.2052 - val_binary_accuracy: 0.9354\n",
            "Epoch 38/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0937 - binary_accuracy: 0.9806 - val_loss: 0.2019 - val_binary_accuracy: 0.9507\n",
            "Epoch 39/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1345 - binary_accuracy: 0.9706 - val_loss: 0.8769 - val_binary_accuracy: 0.6956\n",
            "Epoch 40/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1912 - binary_accuracy: 0.9562 - val_loss: 2.5484 - val_binary_accuracy: 0.5085\n",
            "Epoch 41/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1757 - binary_accuracy: 0.9592 - val_loss: 0.2272 - val_binary_accuracy: 0.9473\n",
            "Epoch 42/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1166 - binary_accuracy: 0.9728 - val_loss: 0.2845 - val_binary_accuracy: 0.9090\n",
            "Epoch 43/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1410 - binary_accuracy: 0.9658 - val_loss: 1.1064 - val_binary_accuracy: 0.7134\n",
            "Epoch 44/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.1438 - binary_accuracy: 0.9675 - val_loss: 0.2791 - val_binary_accuracy: 0.9243\n",
            "Epoch 45/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0934 - binary_accuracy: 0.9761 - val_loss: 0.2144 - val_binary_accuracy: 0.9439\n",
            "Epoch 46/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0603 - binary_accuracy: 0.9887 - val_loss: 0.2115 - val_binary_accuracy: 0.9422\n",
            "Epoch 47/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0493 - binary_accuracy: 0.9917 - val_loss: 0.2479 - val_binary_accuracy: 0.9337\n",
            "Epoch 48/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0485 - binary_accuracy: 0.9914 - val_loss: 0.2316 - val_binary_accuracy: 0.9379\n",
            "Epoch 49/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0387 - binary_accuracy: 0.9927 - val_loss: 0.2378 - val_binary_accuracy: 0.9371\n",
            "Epoch 50/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0361 - binary_accuracy: 0.9932 - val_loss: 0.2238 - val_binary_accuracy: 0.9405\n",
            "Epoch 51/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0350 - binary_accuracy: 0.9952 - val_loss: 0.2285 - val_binary_accuracy: 0.9388\n",
            "Epoch 52/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0291 - binary_accuracy: 0.9950 - val_loss: 0.2302 - val_binary_accuracy: 0.9388\n",
            "Epoch 53/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0287 - binary_accuracy: 0.9967 - val_loss: 0.2269 - val_binary_accuracy: 0.9396\n",
            "Epoch 54/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0234 - binary_accuracy: 0.9960 - val_loss: 0.2454 - val_binary_accuracy: 0.9320\n",
            "Epoch 55/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0238 - binary_accuracy: 0.9965 - val_loss: 0.2300 - val_binary_accuracy: 0.9439\n",
            "Epoch 56/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0231 - binary_accuracy: 0.9975 - val_loss: 0.2339 - val_binary_accuracy: 0.9396\n",
            "Epoch 57/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0194 - binary_accuracy: 0.9975 - val_loss: 0.2509 - val_binary_accuracy: 0.9371\n",
            "Epoch 58/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0283 - binary_accuracy: 0.9952 - val_loss: 0.2397 - val_binary_accuracy: 0.9413\n",
            "Epoch 59/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0194 - binary_accuracy: 0.9977 - val_loss: 0.2661 - val_binary_accuracy: 0.9311\n",
            "Epoch 60/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0158 - binary_accuracy: 0.9980 - val_loss: 0.2385 - val_binary_accuracy: 0.9456\n",
            "Epoch 61/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0144 - binary_accuracy: 0.9975 - val_loss: 0.2464 - val_binary_accuracy: 0.9439\n",
            "Epoch 62/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0156 - binary_accuracy: 0.9982 - val_loss: 0.2704 - val_binary_accuracy: 0.9320\n",
            "Epoch 63/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0153 - binary_accuracy: 0.9975 - val_loss: 0.2611 - val_binary_accuracy: 0.9345\n",
            "Epoch 64/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0148 - binary_accuracy: 0.9982 - val_loss: 0.2741 - val_binary_accuracy: 0.9311\n",
            "Epoch 65/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0134 - binary_accuracy: 0.9990 - val_loss: 0.2473 - val_binary_accuracy: 0.9447\n",
            "Epoch 66/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0090 - binary_accuracy: 0.9990 - val_loss: 0.2446 - val_binary_accuracy: 0.9447\n",
            "Epoch 67/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0156 - binary_accuracy: 0.9970 - val_loss: 0.2643 - val_binary_accuracy: 0.9354\n",
            "Epoch 68/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0118 - binary_accuracy: 0.9990 - val_loss: 0.2763 - val_binary_accuracy: 0.9371\n",
            "Epoch 69/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0105 - binary_accuracy: 0.9985 - val_loss: 0.2587 - val_binary_accuracy: 0.9413\n",
            "Epoch 70/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0097 - binary_accuracy: 0.9990 - val_loss: 0.2638 - val_binary_accuracy: 0.9379\n",
            "Epoch 71/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0117 - binary_accuracy: 0.9985 - val_loss: 0.2681 - val_binary_accuracy: 0.9371\n",
            "Epoch 72/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0104 - binary_accuracy: 0.9985 - val_loss: 0.2671 - val_binary_accuracy: 0.9379\n",
            "Epoch 73/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0089 - binary_accuracy: 0.9992 - val_loss: 0.2664 - val_binary_accuracy: 0.9379\n",
            "Epoch 74/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0105 - binary_accuracy: 0.9990 - val_loss: 0.2640 - val_binary_accuracy: 0.9362\n",
            "Epoch 75/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0072 - binary_accuracy: 0.9995 - val_loss: 0.2689 - val_binary_accuracy: 0.9371\n",
            "Epoch 76/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0074 - binary_accuracy: 0.9992 - val_loss: 0.2677 - val_binary_accuracy: 0.9362\n",
            "Epoch 77/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0075 - binary_accuracy: 0.9990 - val_loss: 0.2624 - val_binary_accuracy: 0.9379\n",
            "Epoch 78/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0092 - binary_accuracy: 0.9995 - val_loss: 0.2668 - val_binary_accuracy: 0.9362\n",
            "Epoch 79/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0090 - binary_accuracy: 0.9995 - val_loss: 0.2837 - val_binary_accuracy: 0.9345\n",
            "Epoch 80/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0076 - binary_accuracy: 0.9990 - val_loss: 0.2729 - val_binary_accuracy: 0.9362\n",
            "Epoch 81/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0066 - binary_accuracy: 0.9992 - val_loss: 0.2695 - val_binary_accuracy: 0.9371\n",
            "Epoch 82/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0067 - binary_accuracy: 0.9995 - val_loss: 0.2685 - val_binary_accuracy: 0.9371\n",
            "Epoch 83/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0077 - binary_accuracy: 0.9985 - val_loss: 0.2696 - val_binary_accuracy: 0.9371\n",
            "Epoch 84/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0093 - binary_accuracy: 0.9990 - val_loss: 0.2737 - val_binary_accuracy: 0.9371\n",
            "Epoch 85/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0075 - binary_accuracy: 0.9995 - val_loss: 0.2712 - val_binary_accuracy: 0.9362\n",
            "Epoch 86/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0060 - binary_accuracy: 0.9995 - val_loss: 0.2705 - val_binary_accuracy: 0.9371\n",
            "Epoch 87/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0077 - binary_accuracy: 0.9995 - val_loss: 0.2683 - val_binary_accuracy: 0.9388\n",
            "Epoch 88/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0055 - binary_accuracy: 0.9995 - val_loss: 0.2725 - val_binary_accuracy: 0.9371\n",
            "Epoch 89/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0077 - binary_accuracy: 0.9995 - val_loss: 0.2743 - val_binary_accuracy: 0.9371\n",
            "Epoch 90/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0055 - binary_accuracy: 0.9995 - val_loss: 0.2711 - val_binary_accuracy: 0.9379\n",
            "Epoch 91/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0091 - binary_accuracy: 0.9987 - val_loss: 0.2695 - val_binary_accuracy: 0.9396\n",
            "Epoch 92/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0058 - binary_accuracy: 0.9997 - val_loss: 0.2814 - val_binary_accuracy: 0.9354\n",
            "Epoch 93/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0065 - binary_accuracy: 0.9990 - val_loss: 0.2840 - val_binary_accuracy: 0.9354\n",
            "Epoch 94/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0060 - binary_accuracy: 0.9992 - val_loss: 0.2751 - val_binary_accuracy: 0.9354\n",
            "Epoch 95/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0057 - binary_accuracy: 0.9997 - val_loss: 0.2736 - val_binary_accuracy: 0.9371\n",
            "Epoch 96/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0073 - binary_accuracy: 0.9995 - val_loss: 0.2759 - val_binary_accuracy: 0.9362\n",
            "Epoch 97/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0086 - binary_accuracy: 0.9992 - val_loss: 0.2773 - val_binary_accuracy: 0.9362\n",
            "Epoch 98/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0060 - binary_accuracy: 0.9997 - val_loss: 0.2775 - val_binary_accuracy: 0.9362\n",
            "Epoch 99/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0074 - binary_accuracy: 0.9985 - val_loss: 0.2764 - val_binary_accuracy: 0.9354\n",
            "Epoch 100/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0058 - binary_accuracy: 0.9997 - val_loss: 0.2742 - val_binary_accuracy: 0.9354\n",
            "Epoch 101/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0076 - binary_accuracy: 0.9990 - val_loss: 0.2741 - val_binary_accuracy: 0.9354\n",
            "Epoch 102/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0060 - binary_accuracy: 0.9997 - val_loss: 0.2746 - val_binary_accuracy: 0.9354\n",
            "Epoch 103/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0063 - binary_accuracy: 0.9997 - val_loss: 0.2760 - val_binary_accuracy: 0.9354\n",
            "Epoch 104/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0075 - binary_accuracy: 0.9997 - val_loss: 0.2779 - val_binary_accuracy: 0.9345\n",
            "Epoch 105/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0078 - binary_accuracy: 0.9990 - val_loss: 0.2755 - val_binary_accuracy: 0.9354\n",
            "Epoch 106/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0063 - binary_accuracy: 0.9995 - val_loss: 0.2744 - val_binary_accuracy: 0.9354\n",
            "Epoch 107/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0071 - binary_accuracy: 0.9992 - val_loss: 0.2735 - val_binary_accuracy: 0.9379\n",
            "Epoch 108/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0044 - binary_accuracy: 0.9997 - val_loss: 0.2734 - val_binary_accuracy: 0.9379\n",
            "Epoch 109/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0113 - binary_accuracy: 0.9982 - val_loss: 0.2737 - val_binary_accuracy: 0.9371\n",
            "Epoch 110/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0049 - binary_accuracy: 0.9997 - val_loss: 0.2736 - val_binary_accuracy: 0.9371\n",
            "Epoch 111/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0072 - binary_accuracy: 0.9992 - val_loss: 0.2717 - val_binary_accuracy: 0.9379\n",
            "Epoch 112/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0071 - binary_accuracy: 0.9995 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 113/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0077 - binary_accuracy: 0.9995 - val_loss: 0.2720 - val_binary_accuracy: 0.9379\n",
            "Epoch 114/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0058 - binary_accuracy: 0.9997 - val_loss: 0.2735 - val_binary_accuracy: 0.9379\n",
            "Epoch 115/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0059 - binary_accuracy: 0.9992 - val_loss: 0.2740 - val_binary_accuracy: 0.9371\n",
            "Epoch 116/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0059 - binary_accuracy: 0.9992 - val_loss: 0.2712 - val_binary_accuracy: 0.9396\n",
            "Epoch 117/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0063 - binary_accuracy: 0.9992 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 118/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0052 - binary_accuracy: 0.9995 - val_loss: 0.2716 - val_binary_accuracy: 0.9388\n",
            "Epoch 119/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0085 - binary_accuracy: 0.9992 - val_loss: 0.2716 - val_binary_accuracy: 0.9379\n",
            "Epoch 120/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0054 - binary_accuracy: 0.9992 - val_loss: 0.2734 - val_binary_accuracy: 0.9379\n",
            "Epoch 121/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0053 - binary_accuracy: 0.9997 - val_loss: 0.2719 - val_binary_accuracy: 0.9379\n",
            "Epoch 122/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0059 - binary_accuracy: 0.9992 - val_loss: 0.2707 - val_binary_accuracy: 0.9388\n",
            "Epoch 123/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0066 - binary_accuracy: 0.9990 - val_loss: 0.2721 - val_binary_accuracy: 0.9379\n",
            "Epoch 124/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0057 - binary_accuracy: 0.9995 - val_loss: 0.2725 - val_binary_accuracy: 0.9379\n",
            "Epoch 125/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0074 - binary_accuracy: 0.9992 - val_loss: 0.2726 - val_binary_accuracy: 0.9379\n",
            "Epoch 126/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0064 - binary_accuracy: 0.9992 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 127/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0057 - binary_accuracy: 0.9995 - val_loss: 0.2732 - val_binary_accuracy: 0.9379\n",
            "Epoch 128/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0049 - binary_accuracy: 0.9997 - val_loss: 0.2730 - val_binary_accuracy: 0.9379\n",
            "Epoch 129/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0061 - binary_accuracy: 0.9995 - val_loss: 0.2714 - val_binary_accuracy: 0.9379\n",
            "Epoch 130/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0056 - binary_accuracy: 0.9997 - val_loss: 0.2723 - val_binary_accuracy: 0.9379\n",
            "Epoch 131/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0063 - binary_accuracy: 0.9995 - val_loss: 0.2716 - val_binary_accuracy: 0.9379\n",
            "Epoch 132/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0062 - binary_accuracy: 0.9997 - val_loss: 0.2725 - val_binary_accuracy: 0.9379\n",
            "Epoch 133/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0059 - binary_accuracy: 0.9992 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 134/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0072 - binary_accuracy: 0.9995 - val_loss: 0.2742 - val_binary_accuracy: 0.9371\n",
            "Epoch 135/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0065 - binary_accuracy: 0.9997 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 136/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0069 - binary_accuracy: 0.9997 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 137/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0071 - binary_accuracy: 0.9995 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 138/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0072 - binary_accuracy: 0.9992 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 139/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0055 - binary_accuracy: 0.9997 - val_loss: 0.2725 - val_binary_accuracy: 0.9379\n",
            "Epoch 140/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0077 - binary_accuracy: 0.9992 - val_loss: 0.2712 - val_binary_accuracy: 0.9388\n",
            "Epoch 141/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0074 - binary_accuracy: 0.9992 - val_loss: 0.2718 - val_binary_accuracy: 0.9388\n",
            "Epoch 142/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0087 - binary_accuracy: 0.9992 - val_loss: 0.2716 - val_binary_accuracy: 0.9388\n",
            "Epoch 143/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0050 - binary_accuracy: 0.9997 - val_loss: 0.2723 - val_binary_accuracy: 0.9379\n",
            "Epoch 144/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0054 - binary_accuracy: 0.9997 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 145/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0069 - binary_accuracy: 0.9997 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 146/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0056 - binary_accuracy: 0.9997 - val_loss: 0.2706 - val_binary_accuracy: 0.9388\n",
            "Epoch 147/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9997 - val_loss: 0.2707 - val_binary_accuracy: 0.9388\n",
            "Epoch 148/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0087 - binary_accuracy: 0.9992 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 149/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0056 - binary_accuracy: 1.0000 - val_loss: 0.2705 - val_binary_accuracy: 0.9405\n",
            "Epoch 150/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0058 - binary_accuracy: 0.9997 - val_loss: 0.2710 - val_binary_accuracy: 0.9388\n",
            "Epoch 151/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9995 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 152/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0053 - binary_accuracy: 0.9995 - val_loss: 0.2710 - val_binary_accuracy: 0.9388\n",
            "Epoch 153/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9995 - val_loss: 0.2734 - val_binary_accuracy: 0.9371\n",
            "Epoch 154/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0055 - binary_accuracy: 0.9997 - val_loss: 0.2717 - val_binary_accuracy: 0.9388\n",
            "Epoch 155/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0072 - binary_accuracy: 0.9995 - val_loss: 0.2725 - val_binary_accuracy: 0.9379\n",
            "Epoch 156/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0061 - binary_accuracy: 0.9990 - val_loss: 0.2732 - val_binary_accuracy: 0.9379\n",
            "Epoch 157/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0066 - binary_accuracy: 0.9995 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 158/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0067 - binary_accuracy: 0.9990 - val_loss: 0.2733 - val_binary_accuracy: 0.9379\n",
            "Epoch 159/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0073 - binary_accuracy: 0.9990 - val_loss: 0.2713 - val_binary_accuracy: 0.9388\n",
            "Epoch 160/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0062 - binary_accuracy: 0.9995 - val_loss: 0.2719 - val_binary_accuracy: 0.9388\n",
            "Epoch 161/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0078 - binary_accuracy: 0.9997 - val_loss: 0.2737 - val_binary_accuracy: 0.9371\n",
            "Epoch 162/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0064 - binary_accuracy: 0.9997 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 163/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9997 - val_loss: 0.2733 - val_binary_accuracy: 0.9379\n",
            "Epoch 164/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0056 - binary_accuracy: 0.9995 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 165/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0071 - binary_accuracy: 0.9997 - val_loss: 0.2742 - val_binary_accuracy: 0.9371\n",
            "Epoch 166/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0060 - binary_accuracy: 0.9992 - val_loss: 0.2713 - val_binary_accuracy: 0.9388\n",
            "Epoch 167/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0073 - binary_accuracy: 0.9990 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 168/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0055 - binary_accuracy: 0.9997 - val_loss: 0.2712 - val_binary_accuracy: 0.9388\n",
            "Epoch 169/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0054 - binary_accuracy: 0.9997 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 170/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0051 - binary_accuracy: 0.9997 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 171/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0061 - binary_accuracy: 0.9997 - val_loss: 0.2726 - val_binary_accuracy: 0.9379\n",
            "Epoch 172/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9992 - val_loss: 0.2744 - val_binary_accuracy: 0.9371\n",
            "Epoch 173/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0070 - binary_accuracy: 0.9990 - val_loss: 0.2735 - val_binary_accuracy: 0.9371\n",
            "Epoch 174/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0067 - binary_accuracy: 0.9995 - val_loss: 0.2733 - val_binary_accuracy: 0.9371\n",
            "Epoch 175/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0069 - binary_accuracy: 0.9997 - val_loss: 0.2735 - val_binary_accuracy: 0.9371\n",
            "Epoch 176/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0050 - binary_accuracy: 0.9997 - val_loss: 0.2720 - val_binary_accuracy: 0.9379\n",
            "Epoch 177/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9997 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 178/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0073 - binary_accuracy: 0.9995 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 179/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0080 - binary_accuracy: 0.9992 - val_loss: 0.2725 - val_binary_accuracy: 0.9379\n",
            "Epoch 180/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0054 - binary_accuracy: 0.9995 - val_loss: 0.2720 - val_binary_accuracy: 0.9379\n",
            "Epoch 181/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0057 - binary_accuracy: 0.9997 - val_loss: 0.2717 - val_binary_accuracy: 0.9388\n",
            "Epoch 182/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0087 - binary_accuracy: 0.9990 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 183/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0057 - binary_accuracy: 0.9995 - val_loss: 0.2721 - val_binary_accuracy: 0.9379\n",
            "Epoch 184/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0070 - binary_accuracy: 0.9995 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 185/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0077 - binary_accuracy: 0.9997 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 186/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9992 - val_loss: 0.2718 - val_binary_accuracy: 0.9379\n",
            "Epoch 187/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9997 - val_loss: 0.2711 - val_binary_accuracy: 0.9388\n",
            "Epoch 188/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0065 - binary_accuracy: 0.9992 - val_loss: 0.2709 - val_binary_accuracy: 0.9388\n",
            "Epoch 189/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0071 - binary_accuracy: 0.9995 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 190/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0063 - binary_accuracy: 0.9990 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 191/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0122 - binary_accuracy: 0.9985 - val_loss: 0.2719 - val_binary_accuracy: 0.9388\n",
            "Epoch 192/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0047 - binary_accuracy: 0.9997 - val_loss: 0.2708 - val_binary_accuracy: 0.9388\n",
            "Epoch 193/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0046 - binary_accuracy: 0.9997 - val_loss: 0.2711 - val_binary_accuracy: 0.9388\n",
            "Epoch 194/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0068 - binary_accuracy: 0.9997 - val_loss: 0.2726 - val_binary_accuracy: 0.9379\n",
            "Epoch 195/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0065 - binary_accuracy: 0.9995 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 196/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0069 - binary_accuracy: 0.9992 - val_loss: 0.2718 - val_binary_accuracy: 0.9379\n",
            "Epoch 197/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0074 - binary_accuracy: 0.9995 - val_loss: 0.2720 - val_binary_accuracy: 0.9379\n",
            "Epoch 198/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0077 - binary_accuracy: 0.9995 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 199/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0058 - binary_accuracy: 0.9997 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 200/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0057 - binary_accuracy: 0.9997 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 201/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0076 - binary_accuracy: 0.9995 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 202/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0039 - binary_accuracy: 0.9997 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 203/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 0.9995 - val_loss: 0.2710 - val_binary_accuracy: 0.9388\n",
            "Epoch 204/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0056 - binary_accuracy: 0.9992 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 205/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0054 - binary_accuracy: 0.9995 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 206/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0066 - binary_accuracy: 0.9992 - val_loss: 0.2721 - val_binary_accuracy: 0.9379\n",
            "Epoch 207/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0076 - binary_accuracy: 0.9997 - val_loss: 0.2695 - val_binary_accuracy: 0.9405\n",
            "Epoch 208/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0051 - binary_accuracy: 0.9997 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 209/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0053 - binary_accuracy: 0.9997 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 210/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0069 - binary_accuracy: 0.9995 - val_loss: 0.2732 - val_binary_accuracy: 0.9379\n",
            "Epoch 211/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0048 - binary_accuracy: 0.9997 - val_loss: 0.2731 - val_binary_accuracy: 0.9371\n",
            "Epoch 212/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0050 - binary_accuracy: 0.9997 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 213/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0066 - binary_accuracy: 0.9997 - val_loss: 0.2720 - val_binary_accuracy: 0.9379\n",
            "Epoch 214/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0062 - binary_accuracy: 0.9990 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 215/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0078 - binary_accuracy: 0.9995 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 216/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0061 - binary_accuracy: 0.9997 - val_loss: 0.2717 - val_binary_accuracy: 0.9388\n",
            "Epoch 217/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0078 - binary_accuracy: 0.9992 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 218/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0057 - binary_accuracy: 0.9992 - val_loss: 0.2720 - val_binary_accuracy: 0.9379\n",
            "Epoch 219/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 0.9995 - val_loss: 0.2713 - val_binary_accuracy: 0.9388\n",
            "Epoch 220/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0053 - binary_accuracy: 0.9995 - val_loss: 0.2717 - val_binary_accuracy: 0.9379\n",
            "Epoch 221/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0075 - binary_accuracy: 0.9992 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 222/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0061 - binary_accuracy: 0.9997 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 223/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9995 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 224/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0054 - binary_accuracy: 1.0000 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 225/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0070 - binary_accuracy: 0.9995 - val_loss: 0.2709 - val_binary_accuracy: 0.9388\n",
            "Epoch 226/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0111 - binary_accuracy: 0.9995 - val_loss: 0.2716 - val_binary_accuracy: 0.9388\n",
            "Epoch 227/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 0.9997 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 228/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0057 - binary_accuracy: 0.9995 - val_loss: 0.2719 - val_binary_accuracy: 0.9379\n",
            "Epoch 229/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0076 - binary_accuracy: 0.9995 - val_loss: 0.2719 - val_binary_accuracy: 0.9388\n",
            "Epoch 230/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0067 - binary_accuracy: 0.9997 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 231/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0053 - binary_accuracy: 0.9997 - val_loss: 0.2709 - val_binary_accuracy: 0.9388\n",
            "Epoch 232/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0064 - binary_accuracy: 0.9992 - val_loss: 0.2703 - val_binary_accuracy: 0.9396\n",
            "Epoch 233/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0074 - binary_accuracy: 0.9995 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 234/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0080 - binary_accuracy: 0.9992 - val_loss: 0.2720 - val_binary_accuracy: 0.9388\n",
            "Epoch 235/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0044 - binary_accuracy: 0.9995 - val_loss: 0.2726 - val_binary_accuracy: 0.9379\n",
            "Epoch 236/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0077 - binary_accuracy: 0.9990 - val_loss: 0.2731 - val_binary_accuracy: 0.9379\n",
            "Epoch 237/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0077 - binary_accuracy: 0.9997 - val_loss: 0.2746 - val_binary_accuracy: 0.9371\n",
            "Epoch 238/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0080 - binary_accuracy: 0.9992 - val_loss: 0.2740 - val_binary_accuracy: 0.9371\n",
            "Epoch 239/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0050 - binary_accuracy: 0.9997 - val_loss: 0.2708 - val_binary_accuracy: 0.9388\n",
            "Epoch 240/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0051 - binary_accuracy: 0.9995 - val_loss: 0.2720 - val_binary_accuracy: 0.9379\n",
            "Epoch 241/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0057 - binary_accuracy: 0.9997 - val_loss: 0.2710 - val_binary_accuracy: 0.9388\n",
            "Epoch 242/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0049 - binary_accuracy: 0.9995 - val_loss: 0.2708 - val_binary_accuracy: 0.9388\n",
            "Epoch 243/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0055 - binary_accuracy: 0.9995 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 244/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0064 - binary_accuracy: 0.9997 - val_loss: 0.2707 - val_binary_accuracy: 0.9388\n",
            "Epoch 245/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0053 - binary_accuracy: 0.9995 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 246/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0068 - binary_accuracy: 0.9995 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 247/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0066 - binary_accuracy: 0.9995 - val_loss: 0.2711 - val_binary_accuracy: 0.9388\n",
            "Epoch 248/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0061 - binary_accuracy: 0.9995 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 249/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0067 - binary_accuracy: 0.9995 - val_loss: 0.2723 - val_binary_accuracy: 0.9379\n",
            "Epoch 250/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9997 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 251/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9995 - val_loss: 0.2718 - val_binary_accuracy: 0.9379\n",
            "Epoch 252/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0073 - binary_accuracy: 0.9997 - val_loss: 0.2717 - val_binary_accuracy: 0.9388\n",
            "Epoch 253/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 0.9997 - val_loss: 0.2710 - val_binary_accuracy: 0.9388\n",
            "Epoch 254/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0068 - binary_accuracy: 0.9995 - val_loss: 0.2719 - val_binary_accuracy: 0.9379\n",
            "Epoch 255/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9995 - val_loss: 0.2707 - val_binary_accuracy: 0.9388\n",
            "Epoch 256/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0054 - binary_accuracy: 0.9997 - val_loss: 0.2705 - val_binary_accuracy: 0.9388\n",
            "Epoch 257/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0064 - binary_accuracy: 0.9990 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 258/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0070 - binary_accuracy: 0.9992 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 259/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0091 - binary_accuracy: 0.9995 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 260/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0058 - binary_accuracy: 0.9995 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 261/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 0.9997 - val_loss: 0.2729 - val_binary_accuracy: 0.9379\n",
            "Epoch 262/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0054 - binary_accuracy: 0.9997 - val_loss: 0.2738 - val_binary_accuracy: 0.9371\n",
            "Epoch 263/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0088 - binary_accuracy: 0.9990 - val_loss: 0.2717 - val_binary_accuracy: 0.9388\n",
            "Epoch 264/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0094 - binary_accuracy: 0.9995 - val_loss: 0.2719 - val_binary_accuracy: 0.9388\n",
            "Epoch 265/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9997 - val_loss: 0.2716 - val_binary_accuracy: 0.9388\n",
            "Epoch 266/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0051 - binary_accuracy: 0.9992 - val_loss: 0.2711 - val_binary_accuracy: 0.9388\n",
            "Epoch 267/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0053 - binary_accuracy: 0.9997 - val_loss: 0.2735 - val_binary_accuracy: 0.9371\n",
            "Epoch 268/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 0.9995 - val_loss: 0.2727 - val_binary_accuracy: 0.9379\n",
            "Epoch 269/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0067 - binary_accuracy: 0.9995 - val_loss: 0.2725 - val_binary_accuracy: 0.9379\n",
            "Epoch 270/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0063 - binary_accuracy: 0.9997 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 271/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0076 - binary_accuracy: 0.9995 - val_loss: 0.2721 - val_binary_accuracy: 0.9388\n",
            "Epoch 272/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0058 - binary_accuracy: 0.9995 - val_loss: 0.2716 - val_binary_accuracy: 0.9388\n",
            "Epoch 273/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0092 - binary_accuracy: 0.9995 - val_loss: 0.2713 - val_binary_accuracy: 0.9388\n",
            "Epoch 274/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0057 - binary_accuracy: 0.9995 - val_loss: 0.2711 - val_binary_accuracy: 0.9388\n",
            "Epoch 275/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0064 - binary_accuracy: 0.9990 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 276/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0063 - binary_accuracy: 0.9990 - val_loss: 0.2713 - val_binary_accuracy: 0.9379\n",
            "Epoch 277/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0053 - binary_accuracy: 0.9997 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 278/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0061 - binary_accuracy: 0.9995 - val_loss: 0.2715 - val_binary_accuracy: 0.9388\n",
            "Epoch 279/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 0.9997 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 280/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0087 - binary_accuracy: 0.9992 - val_loss: 0.2735 - val_binary_accuracy: 0.9371\n",
            "Epoch 281/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9995 - val_loss: 0.2728 - val_binary_accuracy: 0.9379\n",
            "Epoch 282/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0073 - binary_accuracy: 0.9997 - val_loss: 0.2731 - val_binary_accuracy: 0.9379\n",
            "Epoch 283/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0077 - binary_accuracy: 0.9995 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 284/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0064 - binary_accuracy: 0.9995 - val_loss: 0.2708 - val_binary_accuracy: 0.9388\n",
            "Epoch 285/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0052 - binary_accuracy: 0.9995 - val_loss: 0.2709 - val_binary_accuracy: 0.9388\n",
            "Epoch 286/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9995 - val_loss: 0.2716 - val_binary_accuracy: 0.9388\n",
            "Epoch 287/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9990 - val_loss: 0.2703 - val_binary_accuracy: 0.9405\n",
            "Epoch 288/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0084 - binary_accuracy: 0.9992 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 289/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0055 - binary_accuracy: 0.9992 - val_loss: 0.2714 - val_binary_accuracy: 0.9388\n",
            "Epoch 290/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0055 - binary_accuracy: 0.9995 - val_loss: 0.2708 - val_binary_accuracy: 0.9388\n",
            "Epoch 291/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0081 - binary_accuracy: 0.9990 - val_loss: 0.2724 - val_binary_accuracy: 0.9379\n",
            "Epoch 292/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0067 - binary_accuracy: 0.9990 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 293/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0060 - binary_accuracy: 0.9995 - val_loss: 0.2710 - val_binary_accuracy: 0.9388\n",
            "Epoch 294/300\n",
            "125/125 [==============================] - 10s 78ms/step - loss: 0.0060 - binary_accuracy: 0.9997 - val_loss: 0.2702 - val_binary_accuracy: 0.9388\n",
            "Epoch 295/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0056 - binary_accuracy: 0.9995 - val_loss: 0.2713 - val_binary_accuracy: 0.9388\n",
            "Epoch 296/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0059 - binary_accuracy: 1.0000 - val_loss: 0.2723 - val_binary_accuracy: 0.9379\n",
            "Epoch 297/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0062 - binary_accuracy: 0.9997 - val_loss: 0.2718 - val_binary_accuracy: 0.9388\n",
            "Epoch 298/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0063 - binary_accuracy: 0.9995 - val_loss: 0.2722 - val_binary_accuracy: 0.9379\n",
            "Epoch 299/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0067 - binary_accuracy: 0.9995 - val_loss: 0.2716 - val_binary_accuracy: 0.9379\n",
            "Epoch 300/300\n",
            "125/125 [==============================] - 10s 77ms/step - loss: 0.0055 - binary_accuracy: 0.9997 - val_loss: 0.2705 - val_binary_accuracy: 0.9388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "X5ZwawaIam3W",
        "outputId": "bfb0188c-0a4f-4912-8a9c-e665b7d37b00"
      },
      "source": [
        "# list all data in history\n",
        "# print(model_history.history.keys())\n",
        "\n",
        "model_history = model_1_his\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['binary_accuracy'])\n",
        "plt.plot(model_history.history['val_binary_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "# plt.ylim([0.60, 1.00])\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0loAWIgwORt-"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qqdrq4aTORt_",
        "outputId": "1e5a8f40-1e41-4936-eadc-b83c82101664"
      },
      "source": [
        "model = keras.models.load_model('Training_models/PhysioNet 2017/Model 1/ECG_final_run.hdf5')\n",
        "# model = model_1\n",
        "test_scores = model.evaluate(input_test, output_test, verbose = 0)\n",
        "print(\"Test loss:\", test_scores[0])               # 0.1305         \n",
        "print(\"Test accuracy:\", test_scores[1])           # 0.9650\n",
        "\n",
        "\n",
        "# # Load the Final model\n",
        "\n",
        "\n",
        "# test_scores = model.evaluate(input_test, output_test, verbose = 0)\n",
        "# print(\"Test loss:\", test_scores[0])               # 0.1305         \n",
        "# print(\"Test accuracy:\", test_scores[1])           # 0.9650"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.30817005038261414\n",
            "Test accuracy: 0.9365079402923584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEO1GMmaoBJM"
      },
      "source": [
        "yhat = (model.predict(input_test) > 0.5).astype(\"int32\")\n",
        "\n",
        "conf_matrix = confusion_matrix(output_test,yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "mqWGWfQyoBJM",
        "outputId": "4e7c7b88-8c78-4ac7-cc01-1a2c14306fee"
      },
      "source": [
        "# Print the confusion matrix using Matplotlib\n",
        "labels = ['Normal', 'AFib']\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "H-r_XBHzdiaY",
        "outputId": "ad47142d-236b-4fc2-9a31-86efddbbd4b8"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt     \n",
        "\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', ax=ax);  #annot=True to annotate cells, ftm='g' to disable scientific notation\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Normal', 'AFib']); ax.yaxis.set_ticklabels(['Normal', 'AFib']);\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSTrE-dZoBJN",
        "outputId": "789a5025-17a1-44a1-811d-cbec945eee16"
      },
      "source": [
        "accuracy = accuracy_score(output_test, yhat)\n",
        "print('Accuracy:\\t\\t', round(accuracy,4))\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(output_test, yhat)\n",
        "print('Precision:\\t\\t', round(precision,4))\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(output_test, yhat)\n",
        "print('Recall: \\t\\t', round(recall,4))\n",
        "\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(output_test, yhat)\n",
        "print('F1 score:\\t\\t', round(f1,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\t\t 0.9365\n",
            "Precision:\t\t 0.8143\n",
            "Recall: \t\t 0.75\n",
            "F1 score:\t\t 0.7808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNEfFKk4nIix"
      },
      "source": [
        "## 1.2 Model using Augmented data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhhHLWmWqr8U"
      },
      "source": [
        "input_train, output_train, input_test, output_test, input_val, output_val = prepare_data(train_normalised_aug, test_normalised, 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFIZgTOMqr8V",
        "outputId": "eb1abdc4-2243-481a-9322-fb4969516b58"
      },
      "source": [
        "print(\"input train shape:\\t \", input_train.shape)\n",
        "print(\"output train shape:\\t \", output_train.shape)\n",
        "\n",
        "print(\"\\ninput test shape:\\t \", input_test.shape)\n",
        "print(\"output test shape:\\t \", output_test.shape)\n",
        "\n",
        "print(\"\\ninput val shape:\\t \", input_val.shape)\n",
        "print(\"output val shape:\\t \", output_val.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input train shape:\t  (4334, 9000, 1)\n",
            "output train shape:\t  (4334, 1)\n",
            "\n",
            "input test shape:\t  (504, 9000, 1)\n",
            "output test shape:\t  (504, 1)\n",
            "\n",
            "input val shape:\t  (1176, 9000, 1)\n",
            "output val shape:\t  (1176, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLms__rirpwG",
        "outputId": "e9e518c4-9e6b-45dd-e349-d3535d474b6a"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',np.unique(output_train.flatten()), output_train.flatten())\n",
        "\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "class_weight_dict\n",
        "\n",
        "class_weight_dict_1 = {0: 1.0, 1: 8.0}\n",
        "\n",
        "class_weight_dict_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.0, 1: 8.0}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ91Iss2rpwG"
      },
      "source": [
        "# Defining parameter values\n",
        "epochs          = 300\n",
        "batch_size      = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9jW4eJjrpwH",
        "outputId": "8e98cf31-3f4a-4965-842e-6ab67ed49f1a"
      },
      "source": [
        "model_2 = Sequential()\n",
        "\n",
        "# 64, 64, 32, 16, 8, 32\n",
        "\n",
        "input_shape = (9000, 1)\n",
        "model_2.add(InputLayer(input_shape=input_shape))\n",
        "\n",
        "model_2.add(Conv1D(64, 10,padding='causal', activation=\"tanh\"))\n",
        "model_2.add(MaxPooling1D(4))\n",
        "\n",
        "model_2.add(Conv1D(64, 10,padding='same', activation=\"tanh\"))\n",
        "model_2.add(MaxPooling1D(4))\n",
        "\n",
        "model_2.add(LSTM(32,activation = \"tanh\", return_sequences = True))\n",
        "model_2.add(LSTM(16, activation = \"tanh\", return_sequences = True))\n",
        "model_2.add(LSTM(8, activation = \"tanh\"))\n",
        "\n",
        "model_2.add(Dense(32, activation='tanh'))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_2 (Conv1D)            (None, 9000, 64)          704       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 2250, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_3 (Conv1D)            (None, 2250, 64)          41024     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1 (None, 562, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 562, 32)           12416     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 562, 16)           3136      \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 8)                 800       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 58,529\n",
            "Trainable params: 58,465\n",
            "Non-trainable params: 64\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBtdLjgUrpwH"
      },
      "source": [
        "# model training configuration \n",
        "model_2.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                                    loss      = keras.losses.BinaryCrossentropy(),\n",
        "                                    metrics   = [keras.metrics.BinaryAccuracy()])\n",
        "\n",
        "#SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "\n",
        "# Callback to reduce the learning rate when the validation loss has stopped improving\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 30, mode = 'min')\n",
        "\n",
        "# Callback to stop training the model when the validation loss has stopped improving\n",
        "# early_stop = keras.callbacks.EarlyStopping(monitor = 'val_loss', patience = 50, mode = 'min')\n",
        "\n",
        "# CHECKPOINT callback\n",
        "filepath = \"Training_models/PhysioNet 2017/Model 2/ECG.epoch_{epoch:02d}.TL_{loss:.4f}.VL_{val_loss:.4f}.TA_{binary_accuracy:.2f}.VA_{val_binary_accuracy:.2f}.hdf5\"\n",
        "\n",
        "# Save training model when there is an improvement in validation_accuracy from the previous checkpint\n",
        "model_save = keras.callbacks.ModelCheckpoint(filepath, \n",
        "                                             monitor = 'val_binary_accuracy',\n",
        "                                             save_best_only=True, \n",
        "                                             mode = 'max')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "id": "x1zMLhg08TKk",
        "outputId": "75133ab3-0b60-4d57-e283-89a34ea206db"
      },
      "source": [
        "# Fitting the model\n",
        "model_2_his = model_2.fit(input_train, output_train,\n",
        "                          batch_size = batch_size , epochs = epochs, \n",
        "                          validation_data = (input_val, output_val),\n",
        "                          class_weight=class_weight_dict_1,\n",
        "                          callbacks=[reduce_lr,model_save])\n",
        "\n",
        "model_2.save('Training_models/PhysioNet 2017/Model 2/ECG.final_run.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "136/136 [==============================] - 15s 82ms/step - loss: 1.2226 - binary_accuracy: 0.5639 - val_loss: 0.8005 - val_binary_accuracy: 0.1420\n",
            "Epoch 2/300\n",
            "136/136 [==============================] - 10s 76ms/step - loss: 1.1283 - binary_accuracy: 0.6156 - val_loss: 0.6748 - val_binary_accuracy: 0.5859\n",
            "Epoch 3/300\n",
            " 15/136 [==>...........................] - ETA: 8s - loss: 0.9533 - binary_accuracy: 0.6500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-551589aa9ee5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                           \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight_dict_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                           callbacks=[reduce_lr,model_save])\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training_models/PhysioNet 2017/Model 2/ECG.final_run.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1187\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \"\"\"\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    313\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1028\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    510\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 512\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    513\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \"\"\"\n\u001b[1;32m   1093\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1058\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6D01tyLbleJ"
      },
      "source": [
        "# list all data in history\n",
        "# print(model_history.history.keys())\n",
        "\n",
        "model_history = model_2_his\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.plot(model_history.history['binary_accuracy'])\n",
        "plt.plot(model_history.history['val_binary_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "# plt.ylim([0.60, 1.00])\n",
        "plt.legend(['Training', 'Validation'], loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(model_history.history['loss'])\n",
        "plt.plot(model_history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Training', 'Validation'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju_iTrXkTOpe"
      },
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66qFVJJQTOpf"
      },
      "source": [
        "# Load the last checkpoint model\n",
        "# model = keras.models.load_model('Training_models/CNN-LSTM Normal data/Model 4/ECG.epoch_70.TL_0.3511.VL_0.1512.TA_0.91.VA_0.95.hdf5')\n",
        "model = model_2\n",
        "test_scores = model.evaluate(input_test, output_test, verbose = 0)\n",
        "print(\"Test loss:\\t\", test_scores[0])               # 0.1305         \n",
        "print(\"Test accuracy:\", test_scores[1])           # 0.9650"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAHd7NGeooYp"
      },
      "source": [
        "yhat = model.predict_classes(input_test)\n",
        "\n",
        "conf_matrix = confusion_matrix(output_test,yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKrIUWPLooYq"
      },
      "source": [
        "# Print the confusion matrix using Matplotlib\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpusDopqooYr"
      },
      "source": [
        "accuracy = accuracy_score(output_test, yhat)\n",
        "print('Accuracy:\\t\\t', round(accuracy,4))\n",
        "\n",
        "# precision tp / (tp + fp)\n",
        "precision = precision_score(output_test, yhat)\n",
        "print('Precision:\\t\\t', round(precision,4))\n",
        "\n",
        "# recall: tp / (tp + fn)\n",
        "recall = recall_score(output_test, yhat)\n",
        "print('Recall: \\t\\t', round(recall,4))\n",
        "\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "f1 = f1_score(output_test, yhat)\n",
        "print('F1 score:\\t\\t', round(f1,4))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}